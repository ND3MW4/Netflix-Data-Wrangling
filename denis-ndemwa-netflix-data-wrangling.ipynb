{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/denisndemwa/denis-ndemwa-netflix-data-wrangling?scriptVersionId=249977727\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"d0044267","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-07-11T14:16:25.151911Z","iopub.status.busy":"2025-07-11T14:16:25.151582Z","iopub.status.idle":"2025-07-11T14:16:27.079025Z","shell.execute_reply":"2025-07-11T14:16:27.078101Z"},"papermill":{"duration":1.934537,"end_time":"2025-07-11T14:16:27.080736","exception":false,"start_time":"2025-07-11T14:16:25.146199","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/netflix-shows/netflix_titles.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"2f135289","metadata":{"papermill":{"duration":0.002842,"end_time":"2025-07-11T14:16:27.087292","exception":false,"start_time":"2025-07-11T14:16:27.08445","status":"completed"},"tags":[]},"source":["Data Science Project: Data Wrangling\n","This project showcases my walkthrough for data wrangling using python on netflix data.\n","\n","The steps that I will work through are:\n","1. Discovery to understand the data, its existing format and quality.\n","2. Structuring to understand and standardize the formats.\n","3. Cleaning\n","   * Remove Duplicate\n","   * Remove Irrelevant Information\n","   * Handle missing Values\n","   * Handle Outliers\n","4. Enriching\n","5. Validating\n","6. Publishing"]},{"cell_type":"markdown","id":"413cea45","metadata":{"papermill":{"duration":0.002703,"end_time":"2025-07-11T14:16:27.093075","exception":false,"start_time":"2025-07-11T14:16:27.090372","status":"completed"},"tags":[]},"source":[]},{"cell_type":"markdown","id":"0e93ace8","metadata":{"papermill":{"duration":0.00275,"end_time":"2025-07-11T14:16:27.098791","exception":false,"start_time":"2025-07-11T14:16:27.096041","status":"completed"},"tags":[]},"source":["# Step 1:Discovery\n","This is the initial stage where I will explore and understand the data. \n","Key activities include:\n","1. Reviewing data sources and formats.\n","2. Understanding the schema, structure, and relationships.\n","3. Assessing data quality by checking for completeness, accuracy, consistency, and reliability.\n","4. Identifying potential data issues such as missing values, duplicates, or inconsistencies."]},{"cell_type":"code","execution_count":2,"id":"0056646c","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:16:27.106105Z","iopub.status.busy":"2025-07-11T14:16:27.105687Z","iopub.status.idle":"2025-07-11T14:16:27.307293Z","shell.execute_reply":"2025-07-11T14:16:27.306389Z"},"papermill":{"duration":0.207152,"end_time":"2025-07-11T14:16:27.308833","exception":false,"start_time":"2025-07-11T14:16:27.101681","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8807 entries, 0 to 8806\n","Data columns (total 12 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   show_id       8807 non-null   object\n"," 1   type          8807 non-null   object\n"," 2   title         8807 non-null   object\n"," 3   director      6173 non-null   object\n"," 4   cast          7982 non-null   object\n"," 5   country       7976 non-null   object\n"," 6   date_added    8797 non-null   object\n"," 7   release_year  8807 non-null   int64 \n"," 8   rating        8803 non-null   object\n"," 9   duration      8804 non-null   object\n"," 10  listed_in     8807 non-null   object\n"," 11  description   8807 non-null   object\n","dtypes: int64(1), object(11)\n","memory usage: 825.8+ KB\n","Shape of the dataset (R x C): (8807, 12)\n","Columns in the dataset:\n"," ['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'description']\n","Data types:\n"," show_id         object\n","type            object\n","title           object\n","director        object\n","cast            object\n","country         object\n","date_added      object\n","release_year     int64\n","rating          object\n","duration        object\n","listed_in       object\n","description     object\n","dtype: object\n","Missing values per column:\n"," show_id            0\n","type               0\n","title              0\n","director        2634\n","cast             825\n","country          831\n","date_added        10\n","release_year       0\n","rating             4\n","duration           3\n","listed_in          0\n","description        0\n","dtype: int64\n","Number of duplicate rows: 0\n"]}],"source":["#import the Data to a Pandas DataFrame\n","df = pd.read_csv('/kaggle/input/netflix-shows/netflix_titles.csv')\n","\n","#Have a quick overview of the data\n","df.info()\n","\n","df.describe()\n","\n","# Number of rows and columns\n","print(\"Shape of the dataset (R x C):\", df.shape)\n","# List of all column names\n","print(\"Columns in the dataset:\\n\", df.columns.tolist())\n","# Data types of each column\n","print(\"Data types:\\n\", df.dtypes)\n","# Group and Count of missing (null) values in each column\n","print(\"Missing values per column:\\n\", df.isnull().sum())\n","# Group and Count of duplicate rows\n","print(\"Number of duplicate rows:\", df.duplicated().sum())"]},{"cell_type":"markdown","id":"69d632c6","metadata":{"papermill":{"duration":0.003152,"end_time":"2025-07-11T14:16:27.315348","exception":false,"start_time":"2025-07-11T14:16:27.312196","status":"completed"},"tags":[]},"source":["# Step 2: Structuring\n","In this step, the goal is to organize and format the data consistently for easier processing:\n","1. Standardizing column names, data types, and formats.\n","2. Flattening nested structures.\n","3. Pivoting/unpivoting tables, combining multiple sources into a uniform schema.\n","4. Ensuring the data is logically structured to suit downstream analysis or modelling."]},{"cell_type":"code","execution_count":3,"id":"78526e27","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:16:27.323048Z","iopub.status.busy":"2025-07-11T14:16:27.322658Z","iopub.status.idle":"2025-07-11T14:16:27.552038Z","shell.execute_reply":"2025-07-11T14:16:27.551039Z"},"papermill":{"duration":0.235323,"end_time":"2025-07-11T14:16:27.553855","exception":false,"start_time":"2025-07-11T14:16:27.318532","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["      duration_value duration_unit\n","0               90.0           min\n","1                2.0       Seasons\n","2                1.0        Season\n","3                1.0        Season\n","4                2.0       Seasons\n","...              ...           ...\n","8802           158.0           min\n","8803             2.0       Seasons\n","8804            88.0           min\n","8805            88.0           min\n","8806           111.0           min\n","\n","[8807 rows x 2 columns]\n"]}],"source":["# Convert 'date_added' to datetime\n","df['date_added'] = pd.to_datetime(df['date_added'],format='mixed')\n","\n","# Separate 'duration' into numeric value and unit (e.g., '90 min' â†’ 90, 'min')\n","df[['duration_value', 'duration_unit']] = df['duration'].str.extract(r'(\\d+)\\s*(\\w+)')\n","\n","# Convert duration_value to numeric\n","df['duration_value'] = pd.to_numeric(df['duration_value'])\n","\n","# View Resulting columns\n","print(df[['duration_value', 'duration_unit']])"]},{"cell_type":"markdown","id":"62cec8a3","metadata":{"papermill":{"duration":0.003236,"end_time":"2025-07-11T14:16:27.560909","exception":false,"start_time":"2025-07-11T14:16:27.557673","status":"completed"},"tags":[]},"source":["# Step 3: Cleaning\n","This critical phase involves removing or correcting inaccurate or problematic data:\n","1. Check and remove Duplicates: Eliminate repeated records that can skew analysis.\n","2. Remove Irrelevant Information: Drop columns or rows that don't contribute to the analysis.\n","3. Handle Missing Values:\n","    * Remove rows/columns with excessive missingness.\n","    * Impute missing data using mean, median, mode, or predictive techniques.\n","4. Handle Outliers:\n","      * Detect extreme values using statistical methods.\n","      * Remove or cap/floor outliers based on the business context."]},{"cell_type":"code","execution_count":4,"id":"b8b32c79","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:16:27.569151Z","iopub.status.busy":"2025-07-11T14:16:27.568867Z","iopub.status.idle":"2025-07-11T14:16:35.231765Z","shell.execute_reply":"2025-07-11T14:16:35.230691Z"},"papermill":{"duration":7.669016,"end_time":"2025-07-11T14:16:35.233493","exception":false,"start_time":"2025-07-11T14:16:27.564477","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicate rows before: 0\n","Inconsistent date_added vs release_year count: 14\n","     date_added  release_year\n","1551 2020-12-14          2021\n","1696 2020-11-15          2021\n","2920 2020-02-13          2021\n","3168 2019-12-06          2020\n","3287 2019-11-13          2020\n","3369 2019-10-25          2020\n","3433 2019-10-11          2020\n","4844 2018-05-30          2019\n","4845 2018-05-29          2019\n","5394 2017-07-01          2018\n","5658 2016-12-23          2018\n","5677 2016-12-13          2017\n","7063 2018-10-26          2019\n","7112 2013-03-31          2016\n","     show_id     type          title   director  \\\n","1551   s1552  TV Show          Hilda  Not Given   \n","1696   s1697  TV Show   Polly Pocket  Not Given   \n","2920   s2921  TV Show  Love Is Blind  Not Given   \n","3168   s3169  TV Show   Fuller House  Not Given   \n","\n","                                                   cast  \\\n","1551  Bella Ramsey, Ameerah Falzon-Ojo, Oliver Nelso...   \n","1696  Emily Tennant, Shannon Chan-Kent, Kazumi Evans...   \n","2920                        Nick Lachey, Vanessa Lachey   \n","3168  Candace Cameron Bure, Jodie Sweetin, Andrea Ba...   \n","\n","                                    country date_added  release_year rating  \\\n","1551  United Kingdom, Canada, United States 2020-12-14          2021  TV-Y7   \n","1696         Canada, United States, Ireland 2020-11-15          2021   TV-Y   \n","2920                          United States 2020-02-13          2021  TV-MA   \n","3168                          United States 2019-12-06          2020  TV-PG   \n","\n","       duration                      listed_in  duration_value duration_unit  \\\n","1551  2 Seasons                       Kids' TV             2.0       Seasons   \n","1696  2 Seasons                       Kids' TV             2.0       Seasons   \n","2920   1 Season  Reality TV, Romantic TV Shows             1.0        Season   \n","3168  5 Seasons                    TV Comedies             5.0       Seasons   \n","\n","     dir_cast  \n","1551      NaN  \n","1696      NaN  \n","2920      NaN  \n","3168      NaN  \n","Remaining inconsistencies: 14\n"]}],"source":["# Check for duplicate rows\n","print(\"Duplicate rows before:\", df.duplicated().sum())\n","\n","# Drop duplicate rows\n","df = df.drop_duplicates()\n","\n","# Drop description column\n","df = df.drop(columns=['description'])\n","\n","# Impute missing 'director' values using frequent director-cast combinations\n","df['dir_cast'] = df['director'] + '---' + df['cast']\n","counts = df['dir_cast'].value_counts()\n","filtered_counts = counts[counts >= 3]\n","lst_dir_cast = list(filtered_counts.index)\n","\n","dict_direcast = {}\n","for i in lst_dir_cast:\n","    director, cast = i.split('---')\n","    dict_direcast[director] = cast\n","\n","for director, cast in dict_direcast.items():\n","    df.loc[(df['director'].isna()) & (df['cast'] == cast), 'director'] = director\n","\n","# Assign 'Not Given' to all remaining missing directors\n","df.loc[df['director'].isna(), 'director'] = 'Not Given'\n","\n","# Use director to fill missing countries\n","directors = df['director']\n","countries = df['country']\n","pairs = zip(directors, countries)\n","dir_cntry = dict(pairs)\n","\n","for director, country in dir_cntry.items():\n","    df.loc[(df['country'].isna()) & (df['director'] == director), 'country'] = country\n","\n","# Assign 'Not Given' to remaining missing countries\n","df.loc[df['country'].isna(), 'country'] = 'Not Given'\n","\n","# Assign 'Not Given' to remaining missing cast entries\n","df.loc[df['cast'].isna(), 'cast'] = 'Not Given'\n","\n","# Drop rows with missing critical values\n","df.dropna(subset=['date_added', 'rating', 'duration'], inplace=True)\n","\n","# Fixing release year vs date_added inconsistencies\n","import datetime as dt\n","\n","# Ensure 'date_added' is in datetime format\n","df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n","\n","# Check for inconsistencies\n","print(\"Inconsistent date_added vs release_year count:\", sum(df['date_added'].dt.year < df['release_year']))\n","\n","# Show rows with inconsistencies\n","print(df.loc[df['date_added'].dt.year < df['release_year'], ['date_added', 'release_year']])\n","\n","# Sample rows for manual inspection\n","print(df.iloc[[1551, 1696, 2920, 3168]])\n","\n","# Confirm no more release_year inconsistencies\n","print(\"Remaining inconsistencies:\", sum(df['date_added'].dt.year < df['release_year']))"]},{"cell_type":"markdown","id":"a04b556c","metadata":{"papermill":{"duration":0.003463,"end_time":"2025-07-11T14:16:35.240648","exception":false,"start_time":"2025-07-11T14:16:35.237185","status":"completed"},"tags":[]},"source":["# Step 4: Enriching\n","In this stage, I will enhance the dataset by adding meaningful information:\n","1. Merge with external datasets \n","2. Derive new features or calculated fields \n","3. Categorize or bin continuous variables\n"]},{"cell_type":"code","execution_count":5,"id":"db234f82","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:16:35.249463Z","iopub.status.busy":"2025-07-11T14:16:35.249145Z","iopub.status.idle":"2025-07-11T14:16:37.186913Z","shell.execute_reply":"2025-07-11T14:16:37.185883Z"},"papermill":{"duration":1.944226,"end_time":"2025-07-11T14:16:37.188581","exception":false,"start_time":"2025-07-11T14:16:35.244355","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd              # For data manipulation and analysis\n","import numpy as np               # For numerical computations\n","import datetime as dt            # For handling date and time\n","import logging                   # For logging messages and debugging\n","import seaborn as sns            # For statistical data visualization\n","import matplotlib.pyplot as plt  # For general plotting\n","\n","# Setup logging\n","logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n","\n","def remove_duplicates(df):\n","    logging.info(f\"Duplicate rows before: {df.duplicated().sum()}\")\n","    return df.drop_duplicates()\n","\n","def drop_unused_columns(df):\n","    if 'description' in df.columns:\n","        df.drop(columns=['description'], inplace=True)\n","    return df\n","\n","def impute_director(df):\n","    df['dir_cast'] = df['director'].astype(str) + '---' + df['cast'].astype(str)\n","    freq_pairs = df['dir_cast'].value_counts()\n","    reliable_pairs = freq_pairs[freq_pairs >= 3].index\n","\n","    for pair in reliable_pairs:\n","        director, cast = pair.split('---')\n","        df.loc[(df['director'].isna()) & (df['cast'] == cast), 'director'] = director\n","    \n","    df['director'].fillna('Not Given', inplace=True)\n","    df.drop(columns=['dir_cast'], inplace=True)\n","    return df\n","\n","def impute_country(df):\n","    dir_cntry_map = df.dropna(subset=['director', 'country']).drop_duplicates(subset=['director']) \\\n","                      .set_index('director')['country'].to_dict()\n","    df['country'] = df.apply(\n","        lambda x: dir_cntry_map.get(x['director'], 'Not Given') if pd.isna(x['country']) else x['country'], axis=1\n","    )\n","    return df\n","\n","def fill_missing_simple(df):\n","    df['cast'].fillna('Not Given', inplace=True)\n","    return df\n","\n","def drop_rows_with_critical_nulls(df):\n","    return df.dropna(subset=['date_added', 'rating', 'duration'])\n","\n","def fix_and_validate_dates(df):\n","    df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n","    inconsistencies = df[df['date_added'].dt.year < df['release_year']]\n","    logging.info(f\"Inconsistent 'date_added' < 'release_year' rows: {len(inconsistencies)}\")\n","    logging.debug(inconsistencies[['date_added', 'release_year']])\n","    return df\n","\n","def plot_missing_data(df):\n","    plt.figure(figsize=(10, 6))\n","    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n","    plt.title('Missing Data Heatmap')\n","    plt.show()\n","\n","def main(df):\n","    df = remove_duplicates(df)\n","    df = drop_unused_columns(df)\n","    df = impute_director(df)\n","    df = impute_country(df)\n","    df = fill_missing_simple(df)\n","    df = drop_rows_with_critical_nulls(df)\n","    df = fix_and_validate_dates(df)\n","    plot_missing_data(df)\n","    logging.info(\"Data cleaning complete.\")\n","    return df\n","\n","# Example usage\n","# df = pd.read_csv(\"your_dataset.csv\")\n","# df_cleaned = main(df)"]},{"cell_type":"markdown","id":"e1c1d66b","metadata":{"papermill":{"duration":0.003251,"end_time":"2025-07-11T14:16:37.195472","exception":false,"start_time":"2025-07-11T14:16:37.192221","status":"completed"},"tags":[]},"source":["# Step 5: Validating\n","After cleaning and enriching, data is verified for consistency, accuracy, and integrity:\n","1. Remove temporary or wrangling helper columns.\n","2. Ensure correct data types and extracting duration value (numeric) and unit if needed.\n","3. Business logic: Identify records before 1997 (Netflix launch year).\n","4. Check for missing values in key fields.\n","5. Sample a few rows to visually inspect the data\n","6. Reset the index\n","7. Confirm data types"]},{"cell_type":"code","execution_count":6,"id":"14c1398d","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:16:37.203803Z","iopub.status.busy":"2025-07-11T14:16:37.2034Z","iopub.status.idle":"2025-07-11T14:16:37.262186Z","shell.execute_reply":"2025-07-11T14:16:37.260945Z"},"papermill":{"duration":0.064955,"end_time":"2025-07-11T14:16:37.263876","exception":false,"start_time":"2025-07-11T14:16:37.198921","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ðŸ” Records before 1997: 412\n","              title  release_year\n","7           Sankofa          1993\n","22  Avvai Shanmughi          1996\n","41             Jaws          1975\n","42           Jaws 2          1978\n","43           Jaws 3          1983\n","\n","ðŸ§¹ Missing values in key fields:\n","Series([], dtype: int64)\n","\n","ðŸ”Ž Sample records:\n","     show_id     type              title           director  \\\n","456     s457  TV Show   Her Private Life          Not Given   \n","4216   s4217  TV Show            DÃ©jÃ  Vu          Not Given   \n","8461   s8462    Movie  The Polar Express    Robert Zemeckis   \n","8707   s8708    Movie    We, the Marines  Greg MacGillivray   \n","7464   s7465    Movie       Miss Hokusai       Keiichi Hara   \n","\n","                                                   cast        country  \\\n","456   Park Min-young, Kim Jae-uk, Ahn Bo-hyun, Jung ...    South Korea   \n","4216  Mandy Wei, Yao Yuan Hao, Wang Si Ping, Yang Zh...      Not Given   \n","8461  Tom Hanks, Leslie Zemeckis, Eddie Deezen, Nona...  United States   \n","8707                                          Not Given  United States   \n","7464  Anne Watanabe, Yutaka Matsushige, Gaku Hamada,...          Japan   \n","\n","     date_added  release_year rating  duration  \\\n","456  2021-07-15          2019  TV-14  1 Season   \n","4216 2019-01-02          2013  TV-14  1 Season   \n","8461 2021-01-01          2004      G   100 min   \n","8707 2018-07-01          2017  TV-PG    38 min   \n","7464 2017-10-01          2015  PG-13    90 min   \n","\n","                                              listed_in  duration_value  \\\n","456   International TV Shows, Romantic TV Shows, TV ...             1.0   \n","4216  International TV Shows, Romantic TV Shows, TV ...             1.0   \n","8461                           Children & Family Movies           100.0   \n","8707                Documentaries, International Movies            38.0   \n","7464                                     Anime Features            90.0   \n","\n","     duration_unit  \n","456         Season  \n","4216        Season  \n","8461           min  \n","8707           min  \n","7464           min  \n","\n","ðŸ“Š Column data types:\n","show_id                   object\n","type                      object\n","title                     object\n","director                  object\n","cast                      object\n","country                   object\n","date_added        datetime64[ns]\n","release_year               int64\n","rating                    object\n","duration                  object\n","listed_in                 object\n","duration_value           float64\n","duration_unit             object\n","dtype: object\n"]}],"source":["# 1. Remove temporary or wrangling helper columns\n","columns_to_drop = ['dir_cast', 'duration_value', 'duration_unit']\n","df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n","\n","# 2. Ensure correct data types\n","df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n","\n","# Extract duration value (numeric) and unit if needed\n","if 'duration' in df.columns:\n","    df['duration_value'] = df['duration'].str.extract(r'(\\d+)').astype(float)\n","    df['duration_unit'] = df['duration'].str.extract(r'([a-zA-Z]+)').astype(str)\n","\n","# 3. Business logic: Identify records before 1997 (Netflix launch year)\n","pre_1997 = df[df['release_year'] < 1997]\n","print(f\"\\nðŸ” Records before 1997: {len(pre_1997)}\")\n","if not pre_1997.empty:\n","    print(pre_1997[['title', 'release_year']].head())\n","\n","# 4. Check for missing values in key fields\n","key_fields = ['director', 'cast', 'country', 'date_added', 'rating', 'duration']\n","missing_info = df[key_fields].isna().sum()\n","print(\"\\nðŸ§¹ Missing values in key fields:\")\n","print(missing_info[missing_info > 0])\n","\n","# 5. Sample a few rows to visually inspect the data\n","print(\"\\nðŸ”Ž Sample records:\")\n","print(df.sample(5))\n","\n","# 6. Reset the index\n","df = df.reset_index(drop=True)\n","\n","# 7. Confirm data types\n","print(\"\\nðŸ“Š Column data types:\")\n","print(df.dtypes)\n"]},{"cell_type":"markdown","id":"75482678","metadata":{"papermill":{"duration":0.003393,"end_time":"2025-07-11T14:16:37.271137","exception":false,"start_time":"2025-07-11T14:16:37.267744","status":"completed"},"tags":[]},"source":["# Step 6: Publishing\n","Finally, the wrangled data is exported or made accessible for analysis or usage:\n","1. Save in desired formats which is CSV in this case.\n","2. Store in data warehouses, lakes, or BI tools.\n","3. Ensure metadata and documentation are provided for users.\n","4. Set up pipelines for automation if the wrangling process is repeated regularly"]},{"cell_type":"code","execution_count":7,"id":"c4c911ac","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:16:37.279502Z","iopub.status.busy":"2025-07-11T14:16:37.279189Z","iopub.status.idle":"2025-07-11T14:16:37.391431Z","shell.execute_reply":"2025-07-11T14:16:37.390474Z"},"papermill":{"duration":0.118388,"end_time":"2025-07-11T14:16:37.393138","exception":false,"start_time":"2025-07-11T14:16:37.27475","status":"completed"},"tags":[]},"outputs":[],"source":["# Save as CSV \n","df.to_csv('/kaggle/working/cleaned_netflix.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":434238,"sourceId":2654038,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":18.218439,"end_time":"2025-07-11T14:16:38.017642","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-11T14:16:19.799203","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}