{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/denisndemwa/denis-ndemwa-netflix-data-wrangling?scriptVersionId=249979135\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"b26587e3","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-07-11T14:26:50.201403Z","iopub.status.busy":"2025-07-11T14:26:50.200342Z","iopub.status.idle":"2025-07-11T14:26:52.306339Z","shell.execute_reply":"2025-07-11T14:26:52.304856Z"},"papermill":{"duration":2.113688,"end_time":"2025-07-11T14:26:52.308234","exception":false,"start_time":"2025-07-11T14:26:50.194546","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/netflix-shows/netflix_titles.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","id":"1cbdb37c","metadata":{"papermill":{"duration":0.003317,"end_time":"2025-07-11T14:26:52.315878","exception":false,"start_time":"2025-07-11T14:26:52.312561","status":"completed"},"tags":[]},"source":["Data Science Project: Data Wrangling\n","This project showcases my walkthrough for data wrangling using python on netflix data.\n","\n","The steps that I will work through are:\n","1. Discovery to understand the data, its existing format and quality.\n","2. Structuring to understand and standardize the formats.\n","3. Cleaning\n","   * Remove Duplicate\n","   * Remove Irrelevant Information\n","   * Handle missing Values\n","   * Handle Outliers\n","4. Enriching\n","5. Validating\n","6. Publishing"]},{"cell_type":"markdown","id":"6eb830f8","metadata":{"papermill":{"duration":0.003216,"end_time":"2025-07-11T14:26:52.322727","exception":false,"start_time":"2025-07-11T14:26:52.319511","status":"completed"},"tags":[]},"source":[]},{"cell_type":"markdown","id":"3cf40af6","metadata":{"papermill":{"duration":0.003096,"end_time":"2025-07-11T14:26:52.329365","exception":false,"start_time":"2025-07-11T14:26:52.326269","status":"completed"},"tags":[]},"source":["# Step 1:Discovery\n","This is the initial stage where I will explore and understand the data. \n","Key activities include:\n","1. Reviewing data sources and formats.\n","2. Understanding the schema, structure, and relationships.\n","3. Assessing data quality by checking for completeness, accuracy, consistency, and reliability.\n","4. Identifying potential data issues such as missing values, duplicates, or inconsistencies."]},{"cell_type":"code","execution_count":2,"id":"5c7a0335","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:26:52.337699Z","iopub.status.busy":"2025-07-11T14:26:52.337281Z","iopub.status.idle":"2025-07-11T14:26:52.554844Z","shell.execute_reply":"2025-07-11T14:26:52.553548Z"},"papermill":{"duration":0.223958,"end_time":"2025-07-11T14:26:52.556728","exception":false,"start_time":"2025-07-11T14:26:52.33277","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 8807 entries, 0 to 8806\n","Data columns (total 12 columns):\n"," #   Column        Non-Null Count  Dtype \n","---  ------        --------------  ----- \n"," 0   show_id       8807 non-null   object\n"," 1   type          8807 non-null   object\n"," 2   title         8807 non-null   object\n"," 3   director      6173 non-null   object\n"," 4   cast          7982 non-null   object\n"," 5   country       7976 non-null   object\n"," 6   date_added    8797 non-null   object\n"," 7   release_year  8807 non-null   int64 \n"," 8   rating        8803 non-null   object\n"," 9   duration      8804 non-null   object\n"," 10  listed_in     8807 non-null   object\n"," 11  description   8807 non-null   object\n","dtypes: int64(1), object(11)\n","memory usage: 825.8+ KB\n","Shape of the dataset (R x C): (8807, 12)\n","Columns in the dataset:\n"," ['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'description']\n","Data types:\n"," show_id         object\n","type            object\n","title           object\n","director        object\n","cast            object\n","country         object\n","date_added      object\n","release_year     int64\n","rating          object\n","duration        object\n","listed_in       object\n","description     object\n","dtype: object\n","Missing values per column:\n"," show_id            0\n","type               0\n","title              0\n","director        2634\n","cast             825\n","country          831\n","date_added        10\n","release_year       0\n","rating             4\n","duration           3\n","listed_in          0\n","description        0\n","dtype: int64\n","Number of duplicate rows: 0\n"]}],"source":["#import the Data to a Pandas DataFrame\n","df = pd.read_csv('/kaggle/input/netflix-shows/netflix_titles.csv')\n","\n","#Have a quick overview of the data\n","df.info()\n","\n","df.describe()\n","\n","# Number of rows and columns\n","print(\"Shape of the dataset (R x C):\", df.shape)\n","# List of all column names\n","print(\"Columns in the dataset:\\n\", df.columns.tolist())\n","# Data types of each column\n","print(\"Data types:\\n\", df.dtypes)\n","# Group and Count of missing (null) values in each column\n","print(\"Missing values per column:\\n\", df.isnull().sum())\n","# Group and Count of duplicate rows\n","print(\"Number of duplicate rows:\", df.duplicated().sum())"]},{"cell_type":"markdown","id":"41a2cbbc","metadata":{"papermill":{"duration":0.003551,"end_time":"2025-07-11T14:26:52.564126","exception":false,"start_time":"2025-07-11T14:26:52.560575","status":"completed"},"tags":[]},"source":["# Step 2: Structuring\n","In this step, the goal is to organize and format the data consistently for easier processing:\n","1. Standardizing column names, data types, and formats.\n","2. Flattening nested structures.\n","3. Pivoting/unpivoting tables, combining multiple sources into a uniform schema.\n","4. Ensuring the data is logically structured to suit downstream analysis or modelling."]},{"cell_type":"code","execution_count":3,"id":"cd79c47c","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:26:52.572694Z","iopub.status.busy":"2025-07-11T14:26:52.57234Z","iopub.status.idle":"2025-07-11T14:26:52.831959Z","shell.execute_reply":"2025-07-11T14:26:52.830888Z"},"papermill":{"duration":0.265848,"end_time":"2025-07-11T14:26:52.833587","exception":false,"start_time":"2025-07-11T14:26:52.567739","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["      duration_value duration_unit\n","0               90.0           min\n","1                2.0       Seasons\n","2                1.0        Season\n","3                1.0        Season\n","4                2.0       Seasons\n","...              ...           ...\n","8802           158.0           min\n","8803             2.0       Seasons\n","8804            88.0           min\n","8805            88.0           min\n","8806           111.0           min\n","\n","[8807 rows x 2 columns]\n"]}],"source":["# Convert 'date_added' to datetime\n","df['date_added'] = pd.to_datetime(df['date_added'],format='mixed')\n","\n","# Separate 'duration' into numeric value and unit (e.g., '90 min' â†’ 90, 'min')\n","df[['duration_value', 'duration_unit']] = df['duration'].str.extract(r'(\\d+)\\s*(\\w+)')\n","\n","# Convert duration_value to numeric\n","df['duration_value'] = pd.to_numeric(df['duration_value'])\n","\n","# View Resulting columns\n","print(df[['duration_value', 'duration_unit']])"]},{"cell_type":"markdown","id":"2aa70a0d","metadata":{"papermill":{"duration":0.003724,"end_time":"2025-07-11T14:26:52.841329","exception":false,"start_time":"2025-07-11T14:26:52.837605","status":"completed"},"tags":[]},"source":["# Step 3: Cleaning\n","This critical phase involves removing or correcting inaccurate or problematic data:\n","1. Checking and removing duplicates: Eliminates repeated records that can skew analysis.\n","2. Removing irrelevant information: Drop columns or rows that don't contribute to the analysis.\n","3. Handling missing Values:\n","    * Removing rows/columns with excessive missingness.\n","    * Imputing missing data using mean, median, mode, or predictive techniques.\n","4. Handling Outliers:\n","      * Detecting extreme values using statistical methods.\n","      * Removing or cap/floor outliers based on the business context."]},{"cell_type":"code","execution_count":4,"id":"3fcef217","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:26:52.851422Z","iopub.status.busy":"2025-07-11T14:26:52.851108Z","iopub.status.idle":"2025-07-11T14:27:00.3294Z","shell.execute_reply":"2025-07-11T14:27:00.32827Z"},"papermill":{"duration":7.485396,"end_time":"2025-07-11T14:27:00.331085","exception":false,"start_time":"2025-07-11T14:26:52.845689","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicate rows before: 0\n","Inconsistent date_added vs release_year count: 14\n","     date_added  release_year\n","1551 2020-12-14          2021\n","1696 2020-11-15          2021\n","2920 2020-02-13          2021\n","3168 2019-12-06          2020\n","3287 2019-11-13          2020\n","3369 2019-10-25          2020\n","3433 2019-10-11          2020\n","4844 2018-05-30          2019\n","4845 2018-05-29          2019\n","5394 2017-07-01          2018\n","5658 2016-12-23          2018\n","5677 2016-12-13          2017\n","7063 2018-10-26          2019\n","7112 2013-03-31          2016\n","     show_id     type          title   director  \\\n","1551   s1552  TV Show          Hilda  Not Given   \n","1696   s1697  TV Show   Polly Pocket  Not Given   \n","2920   s2921  TV Show  Love Is Blind  Not Given   \n","3168   s3169  TV Show   Fuller House  Not Given   \n","\n","                                                   cast  \\\n","1551  Bella Ramsey, Ameerah Falzon-Ojo, Oliver Nelso...   \n","1696  Emily Tennant, Shannon Chan-Kent, Kazumi Evans...   \n","2920                        Nick Lachey, Vanessa Lachey   \n","3168  Candace Cameron Bure, Jodie Sweetin, Andrea Ba...   \n","\n","                                    country date_added  release_year rating  \\\n","1551  United Kingdom, Canada, United States 2020-12-14          2021  TV-Y7   \n","1696         Canada, United States, Ireland 2020-11-15          2021   TV-Y   \n","2920                          United States 2020-02-13          2021  TV-MA   \n","3168                          United States 2019-12-06          2020  TV-PG   \n","\n","       duration                      listed_in  duration_value duration_unit  \\\n","1551  2 Seasons                       Kids' TV             2.0       Seasons   \n","1696  2 Seasons                       Kids' TV             2.0       Seasons   \n","2920   1 Season  Reality TV, Romantic TV Shows             1.0        Season   \n","3168  5 Seasons                    TV Comedies             5.0       Seasons   \n","\n","     dir_cast  \n","1551      NaN  \n","1696      NaN  \n","2920      NaN  \n","3168      NaN  \n","Remaining inconsistencies: 14\n"]}],"source":["# Check for duplicate rows\n","print(\"Duplicate rows before:\", df.duplicated().sum())\n","\n","# Drop duplicate rows\n","df = df.drop_duplicates()\n","\n","# Drop description column\n","df = df.drop(columns=['description'])\n","\n","# Impute missing 'director' values using frequent director-cast combinations\n","df['dir_cast'] = df['director'] + '---' + df['cast']\n","counts = df['dir_cast'].value_counts()\n","filtered_counts = counts[counts >= 3]\n","lst_dir_cast = list(filtered_counts.index)\n","\n","dict_direcast = {}\n","for i in lst_dir_cast:\n","    director, cast = i.split('---')\n","    dict_direcast[director] = cast\n","\n","for director, cast in dict_direcast.items():\n","    df.loc[(df['director'].isna()) & (df['cast'] == cast), 'director'] = director\n","\n","# Assign 'Not Given' to all remaining missing directors\n","df.loc[df['director'].isna(), 'director'] = 'Not Given'\n","\n","# Use director to fill missing countries\n","directors = df['director']\n","countries = df['country']\n","pairs = zip(directors, countries)\n","dir_cntry = dict(pairs)\n","\n","for director, country in dir_cntry.items():\n","    df.loc[(df['country'].isna()) & (df['director'] == director), 'country'] = country\n","\n","# Assign 'Not Given' to remaining missing countries\n","df.loc[df['country'].isna(), 'country'] = 'Not Given'\n","\n","# Assign 'Not Given' to remaining missing cast entries\n","df.loc[df['cast'].isna(), 'cast'] = 'Not Given'\n","\n","# Drop rows with missing critical values\n","df.dropna(subset=['date_added', 'rating', 'duration'], inplace=True)\n","\n","# Fixing release year vs date_added inconsistencies\n","import datetime as dt\n","\n","# Ensure 'date_added' is in datetime format\n","df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n","\n","# Check for inconsistencies\n","print(\"Inconsistent date_added vs release_year count:\", sum(df['date_added'].dt.year < df['release_year']))\n","\n","# Show rows with inconsistencies\n","print(df.loc[df['date_added'].dt.year < df['release_year'], ['date_added', 'release_year']])\n","\n","# Sample rows for manual inspection\n","print(df.iloc[[1551, 1696, 2920, 3168]])\n","\n","# Confirm no more release_year inconsistencies\n","print(\"Remaining inconsistencies:\", sum(df['date_added'].dt.year < df['release_year']))"]},{"cell_type":"markdown","id":"10f606fa","metadata":{"papermill":{"duration":0.00364,"end_time":"2025-07-11T14:27:00.338779","exception":false,"start_time":"2025-07-11T14:27:00.335139","status":"completed"},"tags":[]},"source":["# Step 4: Enriching\n","In this stage, I will enhance the dataset by adding meaningful information through:\n","1. Merging with external datasets \n","2. Deriving new features or calculated fields \n","3. Categorizing or bin continuous variables\n"]},{"cell_type":"code","execution_count":5,"id":"de543b3a","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:27:00.348203Z","iopub.status.busy":"2025-07-11T14:27:00.347699Z","iopub.status.idle":"2025-07-11T14:27:02.385087Z","shell.execute_reply":"2025-07-11T14:27:02.38401Z"},"papermill":{"duration":2.044353,"end_time":"2025-07-11T14:27:02.386992","exception":false,"start_time":"2025-07-11T14:27:00.342639","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd              # For data manipulation and analysis\n","import numpy as np               # For numerical computations\n","import datetime as dt            # For handling date and time\n","import logging                   # For logging messages and debugging\n","import seaborn as sns            # For statistical data visualization\n","import matplotlib.pyplot as plt  # For general plotting\n","\n","# Setup logging\n","logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n","\n","def remove_duplicates(df):\n","    logging.info(f\"Duplicate rows before: {df.duplicated().sum()}\")\n","    return df.drop_duplicates()\n","\n","def drop_unused_columns(df):\n","    if 'description' in df.columns:\n","        df.drop(columns=['description'], inplace=True)\n","    return df\n","\n","def impute_director(df):\n","    df['dir_cast'] = df['director'].astype(str) + '---' + df['cast'].astype(str)\n","    freq_pairs = df['dir_cast'].value_counts()\n","    reliable_pairs = freq_pairs[freq_pairs >= 3].index\n","\n","    for pair in reliable_pairs:\n","        director, cast = pair.split('---')\n","        df.loc[(df['director'].isna()) & (df['cast'] == cast), 'director'] = director\n","    \n","    df['director'].fillna('Not Given', inplace=True)\n","    df.drop(columns=['dir_cast'], inplace=True)\n","    return df\n","\n","def impute_country(df):\n","    dir_cntry_map = df.dropna(subset=['director', 'country']).drop_duplicates(subset=['director']) \\\n","                      .set_index('director')['country'].to_dict()\n","    df['country'] = df.apply(\n","        lambda x: dir_cntry_map.get(x['director'], 'Not Given') if pd.isna(x['country']) else x['country'], axis=1\n","    )\n","    return df\n","\n","def fill_missing_simple(df):\n","    df['cast'].fillna('Not Given', inplace=True)\n","    return df\n","\n","def drop_rows_with_critical_nulls(df):\n","    return df.dropna(subset=['date_added', 'rating', 'duration'])\n","\n","def fix_and_validate_dates(df):\n","    df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n","    inconsistencies = df[df['date_added'].dt.year < df['release_year']]\n","    logging.info(f\"Inconsistent 'date_added' < 'release_year' rows: {len(inconsistencies)}\")\n","    logging.debug(inconsistencies[['date_added', 'release_year']])\n","    return df\n","\n","def plot_missing_data(df):\n","    plt.figure(figsize=(10, 6))\n","    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n","    plt.title('Missing Data Heatmap')\n","    plt.show()\n","\n","def main(df):\n","    df = remove_duplicates(df)\n","    df = drop_unused_columns(df)\n","    df = impute_director(df)\n","    df = impute_country(df)\n","    df = fill_missing_simple(df)\n","    df = drop_rows_with_critical_nulls(df)\n","    df = fix_and_validate_dates(df)\n","    plot_missing_data(df)\n","    logging.info(\"Data cleaning complete.\")\n","    return df\n","\n","# Example usage\n","# df = pd.read_csv(\"your_dataset.csv\")\n","# df_cleaned = main(df)"]},{"cell_type":"markdown","id":"3618f9ee","metadata":{"papermill":{"duration":0.003655,"end_time":"2025-07-11T14:27:02.394703","exception":false,"start_time":"2025-07-11T14:27:02.391048","status":"completed"},"tags":[]},"source":["# Step 5: Validating\n","After cleaning and enriching, data is verified for consistency, accuracy, and integrity:\n","1. Removing temporary or wrangling helper columns.\n","2. Ensuring correct data types and extracting duration value (numeric) and unit if needed.\n","3. Business logic: Identifying records before 1997 (Netflix launch year).\n","4. Checking for missing values in key fields.\n","5. Sampling a few rows to visually inspect the data\n","6. Resetting the index\n","7. Confirming data types"]},{"cell_type":"code","execution_count":6,"id":"c71f5aae","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:27:02.4042Z","iopub.status.busy":"2025-07-11T14:27:02.403714Z","iopub.status.idle":"2025-07-11T14:27:02.467643Z","shell.execute_reply":"2025-07-11T14:27:02.466442Z"},"papermill":{"duration":0.070828,"end_time":"2025-07-11T14:27:02.469496","exception":false,"start_time":"2025-07-11T14:27:02.398668","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","ðŸ” Records before 1997: 412\n","              title  release_year\n","7           Sankofa          1993\n","22  Avvai Shanmughi          1996\n","41             Jaws          1975\n","42           Jaws 2          1978\n","43           Jaws 3          1983\n","\n","ðŸ§¹ Missing values in key fields:\n","Series([], dtype: int64)\n","\n","ðŸ”Ž Sample records:\n","     show_id     type                                    title  \\\n","46       s47    Movie                               Safe House   \n","8398   s8399    Movie                              The Lobster   \n","7563   s7564    Movie                 National Parks Adventure   \n","4991   s4992  TV Show                                 A.I.C.O.   \n","1407   s1408    Movie  Pinkfong & Baby Shark's Space Adventure   \n","\n","               director                                               cast  \\\n","46      Daniel Espinosa  Denzel Washington, Ryan Reynolds, Vera Farmiga...   \n","8398   Yorgos Lanthimos  Colin Farrell, Jessica Barden, Rachel Weisz, O...   \n","7563  Greg MacGillivray                                     Robert Redford   \n","4991      Kazuya Murata  Haruka Shiraishi, Yusuke Kobayashi, Makoto Fur...   \n","1407      Byeon Hee-sun  Jo Kyoung-i, Kim Seo-yeong, Kim Eun-ah, Jeong ...   \n","\n","                                                country date_added  \\\n","46                   South Africa, United States, Japan 2021-09-16   \n","8398  Ireland, United Kingdom, Greece, France, Nethe... 2018-12-02   \n","7563                                      United States 2018-02-01   \n","4991                                              Japan 2018-03-09   \n","1407                         United States, South Korea 2021-01-15   \n","\n","      release_year rating  duration  \\\n","46            2012      R   115 min   \n","8398          2015      R   119 min   \n","7563          2016   TV-G    42 min   \n","4991          2018  TV-14  1 Season   \n","1407          2019   TV-Y    65 min   \n","\n","                                            listed_in  duration_value  \\\n","46                                 Action & Adventure           115.0   \n","8398  Comedies, International Movies, Romantic Movies           119.0   \n","7563                                    Documentaries            42.0   \n","4991             Anime Series, International TV Shows             1.0   \n","1407                         Children & Family Movies            65.0   \n","\n","     duration_unit  \n","46             min  \n","8398           min  \n","7563           min  \n","4991        Season  \n","1407           min  \n","\n","ðŸ“Š Column data types:\n","show_id                   object\n","type                      object\n","title                     object\n","director                  object\n","cast                      object\n","country                   object\n","date_added        datetime64[ns]\n","release_year               int64\n","rating                    object\n","duration                  object\n","listed_in                 object\n","duration_value           float64\n","duration_unit             object\n","dtype: object\n"]}],"source":["# 1. Remove temporary or wrangling helper columns\n","columns_to_drop = ['dir_cast', 'duration_value', 'duration_unit']\n","df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n","\n","# 2. Ensure correct data types\n","df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n","\n","# Extract duration value (numeric) and unit if needed\n","if 'duration' in df.columns:\n","    df['duration_value'] = df['duration'].str.extract(r'(\\d+)').astype(float)\n","    df['duration_unit'] = df['duration'].str.extract(r'([a-zA-Z]+)').astype(str)\n","\n","# 3. Business logic: Identify records before 1997 (Netflix launch year)\n","pre_1997 = df[df['release_year'] < 1997]\n","print(f\"\\nðŸ” Records before 1997: {len(pre_1997)}\")\n","if not pre_1997.empty:\n","    print(pre_1997[['title', 'release_year']].head())\n","\n","# 4. Check for missing values in key fields\n","key_fields = ['director', 'cast', 'country', 'date_added', 'rating', 'duration']\n","missing_info = df[key_fields].isna().sum()\n","print(\"\\nðŸ§¹ Missing values in key fields:\")\n","print(missing_info[missing_info > 0])\n","\n","# 5. Sample a few rows to visually inspect the data\n","print(\"\\nðŸ”Ž Sample records:\")\n","print(df.sample(5))\n","\n","# 6. Reset the index\n","df = df.reset_index(drop=True)\n","\n","# 7. Confirm data types\n","print(\"\\nðŸ“Š Column data types:\")\n","print(df.dtypes)\n"]},{"cell_type":"markdown","id":"68710c88","metadata":{"papermill":{"duration":0.004126,"end_time":"2025-07-11T14:27:02.478416","exception":false,"start_time":"2025-07-11T14:27:02.47429","status":"completed"},"tags":[]},"source":["# Step 6: Publishing\n","Finally, the wrangled data is exported or made accessible for analysis or usage:\n","1. Saved in desired formats which is CSV in this case.\n","2. Stored in data warehouses, lakes, or BI tools.\n","3. Ensured metadata and documentation are provided for users.\n","4. Set up pipelines for automation if the wrangling process is repeated regularly"]},{"cell_type":"code","execution_count":7,"id":"aecda9be","metadata":{"execution":{"iopub.execute_input":"2025-07-11T14:27:02.488053Z","iopub.status.busy":"2025-07-11T14:27:02.487672Z","iopub.status.idle":"2025-07-11T14:27:02.585439Z","shell.execute_reply":"2025-07-11T14:27:02.584327Z"},"papermill":{"duration":0.104781,"end_time":"2025-07-11T14:27:02.587317","exception":false,"start_time":"2025-07-11T14:27:02.482536","status":"completed"},"tags":[]},"outputs":[],"source":["# Save as CSV \n","df.to_csv('/kaggle/working/cleaned_netflix.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":434238,"sourceId":2654038,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":19.045621,"end_time":"2025-07-11T14:27:03.212836","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-11T14:26:44.167215","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}